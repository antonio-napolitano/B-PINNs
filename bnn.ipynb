{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9dXHRfn8imXDjXR1T6FsO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/progetto_comp_stat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bDnvJVzXNn7","executionInfo":{"status":"ok","timestamp":1709805776327,"user_tz":-60,"elapsed":17806,"user":{"displayName":"Antonio Napolitano","userId":"09394917420548624620"}},"outputId":"de41daa6-c989-4b91-eebc-86b6073152e7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/MyDrive/progetto_comp_stat\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n"],"metadata":{"id":"qRilVHjkUyIN","executionInfo":{"status":"ok","timestamp":1709805782804,"user_tz":-60,"elapsed":4273,"user":{"displayName":"Antonio Napolitano","userId":"09394917420548624620"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"6QW4y6j1UtHG","executionInfo":{"status":"ok","timestamp":1709805784739,"user_tz":-60,"elapsed":278,"user":{"displayName":"Antonio Napolitano","userId":"09394917420548624620"}}},"outputs":[],"source":["class BNN:\n","    def __init__(self, layers, activation=tf.tanh):\n","        self.L = len(layers) - 1\n","        self.variables = self.init_network(layers)\n","        self.bnn_fn = self.build_bnn()\n","        self.bnn_infer_fn = self.build_infer()\n","        self.activation = activation\n","\n","    def init_network(self, layers):\n","        W, b = [], []\n","        init = tf.zeros\n","        # init = tf.keras.initializers.glorot_normal()\n","        for i in range(self.L):\n","            W += [init(shape=[layers[i], layers[i + 1]], dtype=tf.float32)]\n","            b += [tf.zeros(shape=[1, layers[i + 1]], dtype=tf.float32)]\n","        return W + b\n","\n","    def build_bnn(self):\n","        def _fn(x, variables):\n","            \"\"\"\n","            BNN function, for one realization of the neural network, used for MCMC\n","\n","            Args:\n","            -----\n","            x: input,\n","                tensor, with shape [None, input_dim]\n","            variables: weights and bias,\n","                list of tensors, each one of which has dimension [:, :]\n","\n","            Returns:\n","            --------\n","            y: output,\n","                tensor, with shape [None, output_dim]\n","            \"\"\"\n","            W = variables[: len(variables) // 2]\n","            b = variables[len(variables) // 2 :]\n","            y = x\n","            for i in range(self.L - 1):\n","                y = self.activation(tf.matmul(y, W[i]) + b[i])\n","            return tf.matmul(y, W[-1]) + b[-1]\n","\n","        return _fn\n","\n","    def build_infer(self):\n","        def _fn(x, variables):\n","            \"\"\"\n","            BNN function, for batch of realizations of the neural network, used for inference\n","\n","            Args:\n","            -----\n","            x: input,\n","                tensor, with shape [None, input_dim]\n","            variables: weights and bias,\n","                list of tensors, each one of which has dimension [batch_size, :, :]\n","\n","            Returns:\n","            --------\n","            y: output,\n","                tensor, with shape [batch_size, None, output_dim]\n","            \"\"\"\n","            W = variables[: len(variables) // 2]\n","            b = variables[len(variables) // 2 :]\n","            batch_size = W[0].shape[0]\n","            y = tf.tile(x[None, :, :], [batch_size, 1, 1])\n","            for i in range(self.L - 1):\n","                y = self.activation(tf.einsum(\"Nij,Njk->Nik\", y, W[i]) + b[i])\n","            return tf.einsum(\"Nij,Njk->Nik\", y, W[-1]) + b[-1]\n","\n","        return _fn"]}]}